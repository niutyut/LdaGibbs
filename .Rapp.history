Y <- dbinom(seq(1,20), 20, 0.1)
Z <- dbinom(seq(1, 20), 20, 0.20)
cols <- c("red","blue","yellow")
barplot(c(X,Y,Z),col=cols)
barplot(c(X,Y,Z),col=cols, breaks = 20)
barplot(c(X,Y,Z),col=cols, break = 20)
?barplot
barplot(X)
barplot(Y, add = T, col ="red")
barplot(Z, add = T, col = "blue")
?seq
thetas <- seq(from = 2, to = 20, by = 0.1)
theta <- dbeta(thetas, 2, 20)
plot(theta)
hist(theta)
barplot(theta)
curve(dbeta(x, 2, 20))
xs <- seq(0, 1, 0.001)
plot(dbeta(xs, 2, 20))
hist(dbeta(xs, 2, 20))
hist(dbeta(xs, 2, 20), break = 30)
hist(dbeta(xs, 2, 20), breaks = 30)
hist(dbeta(xs, 2, 20), breaks = 100)
hist(dbeta(xs, 2, 20), breaks = 200)
length(xs)
hist(dbeta(xs, 2, 20), breaks = 1000)
hist(dbeta(xs, 2, 20), breaks = 200)
dbeta(.1, 2, 20)
qbeta(.1, 2, 20)
pbeta(.1, 2, 20)
pbeta(.2, 2, 20) - pbeta(.5, 2, 20)
pbeta(.2, 2, 20) - pbeta(.05, 2, 20)
rmult
?mult
?multinomial
rmultinom(1, 3, c(0.2, 0.3, 0.5))
rmultinom(3, 1, c(0.2, 0.3, 0.5))
rmultinom(1, 3, c(0.2, 0.3, 0.5))
rmultinom(1, 1, c(0.2, 0.3, 0.5))
rmultinom(1, 1, c(0.01, 0.01, 0.98))
rmultinom(20, 1, c(0.01, 0.01, 0.98))
rmultinom(20, 1, c(0, 0, 1))
rmultinom(100, 1, c(0, 0, 1))
rmultinom(1000, 1, c(0, 0, 1))
rmultinom(1000000, 1, c(0, 0, 1))
rmultinom(10000, 1, c(0, 0, 1))
rmultinom(10000, 10, c(.2, .3, .5))
rowMeans(rmultinom(10000, 10, c(.2, .3, .5)))
rowMeans(rmultinom(10000, 10, c(.2, .3, .5)))/10
rowMeans(rmultinom(100000, 10, c(.2, .3, .5)))/10
rowMeans(rmultinom(1000000, 10, c(.2, .3, .5)))/10
rowMeans(rmultinom(100000000, 10, c(.2, .3, .5)))/10
sum(rowMeans(rmultinom(100000, 10, c(.2, .3, .5)))/10)
rowMeans(rmultinom(100000, 10, c(.2, .3, .5)))/10
library(lda)
cora.documents[1]
cora.vocab
cora.vocabulary
library(tm)
data(cora)
demo(lda)
cora.documents[[1]]
data(cora)
quit()
library(ggplot2)
data(diamonds)
dsmall <- diamonds[sample(nrow(diamonds), 100)]
dsmall <- diamonds[sample(nrow(diamonds), 100), ]
dsmall
qplot(carat, count, data = diamonds, geom="histogram", fill = color)
qplot(carat, data = diamonds, geom="histogram", fill = color)
data(economics)
qplot(data, unempoy/ pop, geom ="line")
qplot(date, unempoy/ pop, data = economics, geom ="line")
qplot(date, unemploy/ pop, data = economics, geom ="line")
qplot(date, unempmed, data = economics, geom ="line")
qplot(date, uempmed, data = economics, geom ="line")
year <- function(x) as.POSIXlt(x)$year + 1900
qplot(unemploy / p, uempmed, data = economics, geom = c("point, path"))
qplot(unemploy / p, uempmed, data = economics, geom = c("point", "path"))
qplot(unemploy / pop, uempmed, data = economics, geom = c("point", "path"))
qplot(unemploy / pop, uempmed, data = economics, geom = c("point", "path"), colour = year(data)) + scale_area()
qplot(unemploy / pop, uempmed, data = economics, geom = "path", colour = year(date)) + scale_area()
qplot(carat, data=diamonds, facets = color ~ ., geom = "histogram", binwidth = 0.1, xlim = c(0, 3))
qplot(carat, ..density.., data=diamonds, facets = color ~ ., geom = "histogram", binwidth = 0.1, xlim = c(0, 3))
library(lda)
demo(lda)
library(lda)
demo(lda)
sample(1:dim(topic.proportions)[1], N)
demo(lda)
library(lda)
demo(lda)
tests_dir <- "/Users/jacobmenick/Desktop/Summer_2014_Research/tests/"
ggsave(file=tests_dir + "CRAN_cora_results.pdf")
ggsave(file= tests_dir + "CRAN_cora_results.pdf")
ggsave(file=paste(tests_dir,"CRAN_cora_results.pdf"))
This file runs the analysis on the 'cora' corpus from the CRAN lda package.  #
## We hope to achieve similar results as their demo so as test whether or not #
## this implementation of the Gibbs sampler is correct. #
###
## It assumes our current directory is the root of this project.  #
## We use the same parameters as are used in the demo(lda) script. #
#
# Load functions into workspace#
source("gibbs_prep.R")#
source("Gibbs.R")#
source("gibbs_output.R")#
#
# Load cora dataset into the workspace. #
library(lda)#
data(cora.documents)#
data(cora.vocab)#
#
# Get the dtm for cora. #
dtmCORA <- lda_corpus_to_dtm(cora.documents, cora.vocab)#
#
# Stemify the corpus. #
new_corpus_objects <- stemmify(dtmCORA, cora.vocab)#
dtmCORA <- new_corpus_objects[[1]]#
cora.vocab <- new_corpus_objects[[2]]#
#
# I realize the list operations are probably counterintuitive. #
# I couldn't think of a better way to return multiple objects.#
# The remove.stopwords function affects both the dtm and the vocab, though. #
#
# Remove some stop words. #
stop.words <- c("paper", "result", "model", "show", "method", "approach")#
#
new_corpus_objects <- remove.stopwords(dtmCORA, cora.vocab, stop.words)#
dtmCORA <- new_corpus_objects[[1]]#
cora.vocab <- new_corpus_objects[[2]]#
# Set Parameters for the Gibbs Sampler, #
n.sim <- 25#
K <- 10#
alpha <- 0.1#
beta <- 0.1#
#
# Run Gibbs Sampler and store results in the variable 'paramsCORA'#
paramsCORA <- gibbs.sampler.lda(dtmCORA, n.sim, K, alpha, beta)#
#
# Now let's visualize the results of the model fit with ggplot2. #
#
numDocs <- 10#
#
# Get a melted dataframe#
df <- get_plottable_df_lda(dtmCORA, cora.vocab, paramsCORA, numDocs)#
#
# Plot the results. #
plot <- get_primitive_qplot(df, numDocs)#
print(plot)
library(lda)
demo(lda)
library(lda)
demo(lda)
ggsave(file="/Users/jacobmenick/Desktop/Summer_2014_Research/r_scripts/LdaGibbs/figures/CRAN_cora_results.pdf")
demo(lda)
library(lda)
demo(lda)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar", stat="identity") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar", stat="bin") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(421)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(8675309)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(8675309)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(8675309)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
demo(lda)
topic.proportions.df
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
qplot(topic, value, fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
qplot(topic, value, fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
topic.proportions.df
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
qplot(topic, value/sum(value), fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
qplot(topic, value, fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="bin") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
qplot(topic, value/40, fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
qplot(topic, value, fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
This file runs the analysis on the 'cora' corpus from the CRAN lda package.  #
## 1.  We hope to achieve similar results as #
##     their demo so as test whether or not his implementation of #
##     the Gibbs sampler is correct. #
###
## 2.  It assumes our current directory is the root of this project.  #
##     We use the same parameters as are used in the demo(lda) script. #
###
## 3.  You may want to try a few runs with different seeds.  #
##     Because the Gibbs sampler is non-deterministic, #
##     And we are doing a relatively samll number of iterations,#
##     The initial state of the Markov Chain can have big effects on #
##     the output.  #
#
# Load functions into workspace#
source("gibbs_prep.R")#
source("Gibbs.R")#
source("gibbs_output.R")#
#
# Load cora dataset into the workspace. #
library(lda)#
data(cora.documents)#
data(cora.vocab)#
#
# Get the dtm for cora. #
dtmCORA <- lda_corpus_to_dtm(cora.documents, cora.vocab)#
#
# Convert the dtm to a tm 'corpus' for pre-processing. #
corpusCORA <- dtm_to_corpus(dtmCORA)#
corpusCORA <- process_corpus(corpusCORA)#
corpusCORA <- stem_corpus(corpusCORA)#
#
# Convert back to a dtm.  #
dtmCORA <- get_dtm_matrix(corpusCORA)#
cora.vocab <- get_vocabObj(dtmCORA)#
# Remove some stop words. Blei mentioned in a video that they did this as well.  #
stop.words <- c("paper", "result", "model", "show", "method", "approach", "base", #
                "data", "general", "function", "perform", "comput", "present")#
#
new_corpus_objects <- remove.stopwords(dtmCORA, cora.vocab, stop.words)#
dtmCORA <- new_corpus_objects[[1]]#
cora.vocab <- new_corpus_objects[[2]]#
# Set Parameters for the Gibbs Sampler, #
n.sim <- 25#
K <- 10#
alpha <- 0.1#
beta <- 0.1#
#
# Run Gibbs Sampler and store results in the variable 'paramsCORA'#
paramsCORA <- gibbs.sampler.lda(dtmCORA, n.sim, K, alpha, beta)#
#
# Now let's visualize the results of the model fit with ggplot2. #
#
numDocs <- 10#
#
# Get a melted dataframe#
df <- get_plottable_df_lda(dtmCORA, cora.vocab, paramsCORA, numDocs)#
#
# Plot the results. #
plot <- get_primitive_qplot(df, numDocs)#
print(plot)
library('lda')
demo(lda)
top.words
?apply
top.topic.words
library(mallet)
install.packages('topicwatch')
install.packages('TopicWatch')
library(Rcpp)
cppFunction('int add(int x, int y, int z) {
int sum = x + y + z;
return sum;
}')
library(Rcpp)
sourceCpp("/Users/jacobmenick/Desktop/sandbox/test8.cpp")
path = "/Users/jacobmenick/Desktop/sandbox/test8.cpp"
library(Rcpp)
sourceCpp("path")
sourceCpp(path)
sourceCpp(path)\
sourceCpp(path)
require(Rcpp)#
require(microbenchmark)#
#
sourceCpp("devGibbs.cpp")#
source("gibbs_prep.R")
home_path <- "# This script analyzes the C++ code I for the Gibbs Sampler. #
# Be sure to setwd() to the dir containing this script. #
#
require(Rcpp)#
require(microbenchmark)#
#
sourceCpp("devGibbs.cpp")#
source("gibbs_prep.R")#
# Section 1: BENCHMARKS#
# Benchmark my multinomial sampling code against R's multinomial sampling code.#
probs <- c(.1, .05, .15, .3, .4)#
n.test <- 1000#
#
testOMC <- function(n.test, probs) {#
	s <- length(probs)#
	out <- rep(0, s)#
	for (i in 1:n.test) {#
		vector.sampled <- oneMultinomC(probs)#
		index <- whichC(vector.sampled, 1)#
		out[index + 1] = out[index + 1] + 1#
	}#
	out <- out / n.test#
	rbind(out, probs)#
}#
#
testOMR <- function(n.test, probs) {#
	s <- length(probs)#
	out <- rep(0, s)#
	for (i in 1:n.test) {#
		vector.sampled <- rmultinom(1, 1, probs)#
		index <- which(vector.sampled == 1)#
		out[index] <- out[index] + 1#
	}#
	out <- out / n.test#
	rbind(out, probs)#
}#
#
microbenchmark(#
  testOMC(n.test, probs),#
  testOMR(n.test, probs))#
#
# Benchmark my uniform sampling code against R's uniform sampling code. #
b <- 10#
#
testUnifC <- function(n.test, b) {#
	for (i in 1:n.test) {#
      unif <- cUnifTest(b)		#
    }#
}#
#
testUnifR <- function(n.test, b) {#
	for (i in 1:n.test) {#
      unif <- round(runif(1, 1, b))#
    }#
}#
#
microbenchmark(#
  testUnifC(n.test, b),#
  testUnifR(n.test, b))#
# Section 2: TEST GIBBS SAMPLER#
path_to_reuters <- "text_corpuses/reuters001"#
reuters001 <- get_corpus(path_to_reuters)#
dtm001 <- get_dtm_matrix(reuters001)#
#
K <- 10#
alpha <- 50/K#
beta <- 0.01#
nsim <- 1#
#
# See the output in R for the problems.#
# Note - I haven't included the code for the parameter estimates yet. #
#      - This is only a very little bit of code compared to getting gibbsC working. #
matrices <- gibbsC(dtm001, 1, K, alpha, beta, verbose = F)#
#
# Okay, we see some errors. Let's investigate. #
#
count.matrices.init <- initializeGibbs(dtm001, K)#
#
dtc.init <- count.matrices.init[[1]]#
ttc.init <- count.matrices.init[[2]]#
ta.init <- count.matrices.init[[3]]#
#
# Are these counts tabulated correctly? Let's have a look at document zero. #
# Get the vocab terms that occur in document zero (have greater than one count in dtm)#
doczero <- which(dtm001[1,] > 0)#
#
# Okay, so we can see which words occur in document 0 by having a look at 'doczero'. #
# One such word is '38' if we index at zero (or '39' if we index at 1)#
# Let's see what topic it was assigned in the initialization step. #
#
topiczero.38 <- ta.init[1, 39]#
#
# Okay, this was random, so it will be different for me and you.  For me it's 3. #
# We see from the output that there is an error sampling a new topic for document 0, word 38. Let's try to do it manually: #
#
newZ <- sampler(dtm001, dtc.init, ttc.init, alpha, beta, 0, 38, K)#
"
_))))))
}}}}
)))))@
SDl;kjasf
;xmcvz.xmvxcvzxcjvzl;kxcjvzl;xcjvz;lxckjvz;xclkjvz;xcljvz;xclvjz;xcvjz;xcljvx"
home_dir <- "/Users/jacobmenick/Desktop/Summer_2014_Research/r_scripts/LdaGibbs"
setwd(home_dir)
require(Rcpp)#
require(microbenchmark)#
#
sourceCpp("devGibbs.cpp")#
source("gibbs_prep.R")
path_to_reuters <- "text_corpuses/reuters001"#
reuters001 <- get_corpus(path_to_reuters)#
dtm001 <- get_dtm_matrix(reuters001)#
#
K <- 10#
alpha <- 50/K#
beta <- 0.01#
nsim <- 1
matrices <- gibbsC(dtm001, 1, K, alpha, beta, verbose = F)
count.matrices.init <- initializeGibbs(dtm001, K)
dtc.init <- count.matrices.init[[1]]#
ttc.init <- count.matrices.init[[2]]#
ta.init <- count.matrices.init[[3]]
doczero <- which(dtm001[1,] > 0)
topiczero.38 <- ta.init[1, 39]
newZ <- sampler(dtm001, dtc.init, ttc.init, alpha, beta, 0, 38, K)
newZ
sourceCpp("devGibbs.cpp")
setwd(home_path)
setwd(home_dir)
sourceCpp("devGibbs.cpp")
newZ <- sampler(dtm001, dtc.init, ttc.init, alpha, beta, 0, 38, K)
matrices <- gibbsC(dtm001, 1, K, alpha, beta, verbose = F)
m <- 1#
n <- 39#
#
params.test <- rep(0, K)#
sum <- 0#
#
for (k in 1:K) {#
	prob.test <- ttc[k, n] + beta#
	prob.test <- prob.test * (dtc[m, k] + alpha)#
	prob.test <- prob.test / (rowSum(ttc.init, (k - 1) ) + (beta * V))#
	prob.test <- prob.test / (rowSum(dtc.init, (m - 1) ) + (alpha * K))#
	sum = sum + prob.test#
	params.test[k] <- prob.test#
}
m <- 1#
n <- 39#
#
params.test <- rep(0, K)#
sum <- 0#
#
for (k in 1:K) {#
	prob.test <- ttc.init[k, n] + beta#
	prob.test <- prob.test * (dtc.init[m, k] + alpha)#
	prob.test <- prob.test / (rowSum(ttc.init, (k - 1) ) + (beta * V))#
	prob.test <- prob.test / (rowSum(dtc.init, (m - 1) ) + (alpha * K))#
	sum = sum + prob.test#
	params.test[k] <- prob.test#
}
M <- nrow(dtm001)#
V <- ncol(dtm001)
m <- 1#
n <- 39#
#
params.test <- rep(0, K)#
sum <- 0#
#
for (k in 1:K) {#
	prob.test <- ttc.init[k, n] + beta#
	prob.test <- prob.test * (dtc.init[m, k] + alpha)#
	prob.test <- prob.test / (rowSum(ttc.init, (k - 1) ) + (beta * V))#
	prob.test <- prob.test / (rowSum(dtc.init, (m - 1) ) + (alpha * K))#
	sum = sum + prob.test#
	params.test[k] <- prob.test#
}
params.test
params.test[sort(params.test, decreasing = F)]
sort(params.test)
order(params.test)
params.test[order(params.test)]
cmultinom(params.test, (m - 1), (n -1))
sum
params.test <- params.test / sum
params.test
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
cmultinom(params.test, (m - 1), (n -1))
sourceCpp("devGibbs.cpp")
matrices <- gibbsC(dtm001, 1, K, alpha, beta, verbose = F)
n2 <- 31#
#
for (k in 1:K) {#
	prob.test <- ttc.init[k, n] + beta#
	prob.test <- prob.test * (dtc.init[m, k] + alpha)#
	prob.test <- prob.test / (rowSum(ttc.init, (k - 1) ) + (beta * V))#
	prob.test <- prob.test / (rowSum(dtc.init, (m - 1) ) + (alpha * K))#
	sum = sum + prob.test#
	params.test[k] <- prob.test#
}#
#
params.test
getProbs <- function(m, n, K, V) {#
	params.test <- rep(0, K)#
	for (k in 1:K) {#
		prob.test <- ttc.init[k, n] + beta#
		prob.test <- prob.test * (dtc.init[m, k] + alpha)#
		prob.test <- prob.test / (rowSum(ttc.init, (k - 1) ) + (beta * V))#
		prob.test <- prob.test / (rowSum(dtc.init, (m - 1) ) + (alpha * K))#
		sum = sum + prob.test#
		params.test[k] <- prob.test#
	}#
#
params.test#
}
getProbs(1, 31, K, V)
getProbs(1, 39, K, V)
