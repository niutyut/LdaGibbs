return x^2
squareThisNumber = function(x) {
x^2
}
squareThisNumber(2)
squareThisNumber(4)
squareThisNumber(20)
x <- matrix(c(1, 2, 1, 2, 1, 3), byrow = T, nrow = 3)
x
costFunctionJ = function(X,y,theta) {
m = nrow(X)
predictions = X %*% theta
sqrErrors = (predictions - y)^2
J = 1/(2*m) * sum(sqrErrors)
J
}
y = c(1,2,3)
x
y
theta = c(0,1)
j = costFunctionJ(x,y,theta)
j
theta
X %*% theta
theta <- as.matrix(tehta)
theta <- as.matrix(theta)
X %*% theta
X
x %*% theta
x
x <- matrix(c(1, 1, 1, 2, 1, 3), byrow = T, nrow = 3)
j = costFunctionJ(x,y,theta)
j
data(reuters)
library(tm)
data(reuters)
reuters
library(lda)
demo(lda)
crude <- data(crude)
crude
data("crude")
crude <- data("crude")
crude
library(tm)
crude
tm.crude
?crude
summary(crude)
remove(crude)
library(Tm)
library(tm)
crude
data(crude)
summary(crude)
reut21578 <- system.file("texts", "crude", package = "tm")
reut21578
reuters <- Corpus(DirSource(reut21578),
readerControl = list(reader = readReut21578XML))
reuters
reuters[1]
?readPdf
?readPdf(0)
?readPdf()
?readPDF
curve(dbinom(x, 20, 0.5))
plot(dbinom(x, 20, 0.5))
plot(dbinom(seq(1,20), 20, 0.5))
plot(dbinom(seq(1,20), 20, 0.1))
plot(dbinom(seq(1,20), 20, 0.5))
density(dbinom(seq(1,20), 20, 0.5))
plotdensity(dbinom(seq(1,20), 20, 0.5))
?plo
?plot
plot(density(dbinom(seq(1,20), 20, 0.5)))
X <- dbinom(seq(1,20), 20, 0.5))
X <- dbinom(seq(1,20), 20, 0.5)
plot(X)
?plto
?plot
barplot(X)
X <- dbinom(seq(1, 20), 20, 0.05)
Y <- dbinom(seq(1,20), 20, 0.1)
Z <- dbinom(seq(1, 20), 20, 0.20)
cols <- c("red","blue","yellow")
barplot(c(X,Y,Z),col=cols)
barplot(c(X,Y,Z),col=cols, breaks = 20)
barplot(c(X,Y,Z),col=cols, break = 20)
?barplot
barplot(X)
barplot(Y, add = T, col ="red")
barplot(Z, add = T, col = "blue")
?seq
thetas <- seq(from = 2, to = 20, by = 0.1)
theta <- dbeta(thetas, 2, 20)
plot(theta)
hist(theta)
barplot(theta)
curve(dbeta(x, 2, 20))
xs <- seq(0, 1, 0.001)
plot(dbeta(xs, 2, 20))
hist(dbeta(xs, 2, 20))
hist(dbeta(xs, 2, 20), break = 30)
hist(dbeta(xs, 2, 20), breaks = 30)
hist(dbeta(xs, 2, 20), breaks = 100)
hist(dbeta(xs, 2, 20), breaks = 200)
length(xs)
hist(dbeta(xs, 2, 20), breaks = 1000)
hist(dbeta(xs, 2, 20), breaks = 200)
dbeta(.1, 2, 20)
qbeta(.1, 2, 20)
pbeta(.1, 2, 20)
pbeta(.2, 2, 20) - pbeta(.5, 2, 20)
pbeta(.2, 2, 20) - pbeta(.05, 2, 20)
rmult
?mult
?multinomial
rmultinom(1, 3, c(0.2, 0.3, 0.5))
rmultinom(3, 1, c(0.2, 0.3, 0.5))
rmultinom(1, 3, c(0.2, 0.3, 0.5))
rmultinom(1, 1, c(0.2, 0.3, 0.5))
rmultinom(1, 1, c(0.01, 0.01, 0.98))
rmultinom(20, 1, c(0.01, 0.01, 0.98))
rmultinom(20, 1, c(0, 0, 1))
rmultinom(100, 1, c(0, 0, 1))
rmultinom(1000, 1, c(0, 0, 1))
rmultinom(1000000, 1, c(0, 0, 1))
rmultinom(10000, 1, c(0, 0, 1))
rmultinom(10000, 10, c(.2, .3, .5))
rowMeans(rmultinom(10000, 10, c(.2, .3, .5)))
rowMeans(rmultinom(10000, 10, c(.2, .3, .5)))/10
rowMeans(rmultinom(100000, 10, c(.2, .3, .5)))/10
rowMeans(rmultinom(1000000, 10, c(.2, .3, .5)))/10
rowMeans(rmultinom(100000000, 10, c(.2, .3, .5)))/10
sum(rowMeans(rmultinom(100000, 10, c(.2, .3, .5)))/10)
rowMeans(rmultinom(100000, 10, c(.2, .3, .5)))/10
library(lda)
cora.documents[1]
cora.vocab
cora.vocabulary
library(tm)
data(cora)
demo(lda)
cora.documents[[1]]
data(cora)
quit()
library(ggplot2)
data(diamonds)
dsmall <- diamonds[sample(nrow(diamonds), 100)]
dsmall <- diamonds[sample(nrow(diamonds), 100), ]
dsmall
qplot(carat, count, data = diamonds, geom="histogram", fill = color)
qplot(carat, data = diamonds, geom="histogram", fill = color)
data(economics)
qplot(data, unempoy/ pop, geom ="line")
qplot(date, unempoy/ pop, data = economics, geom ="line")
qplot(date, unemploy/ pop, data = economics, geom ="line")
qplot(date, unempmed, data = economics, geom ="line")
qplot(date, uempmed, data = economics, geom ="line")
year <- function(x) as.POSIXlt(x)$year + 1900
qplot(unemploy / p, uempmed, data = economics, geom = c("point, path"))
qplot(unemploy / p, uempmed, data = economics, geom = c("point", "path"))
qplot(unemploy / pop, uempmed, data = economics, geom = c("point", "path"))
qplot(unemploy / pop, uempmed, data = economics, geom = c("point", "path"), colour = year(data)) + scale_area()
qplot(unemploy / pop, uempmed, data = economics, geom = "path", colour = year(date)) + scale_area()
qplot(carat, data=diamonds, facets = color ~ ., geom = "histogram", binwidth = 0.1, xlim = c(0, 3))
qplot(carat, ..density.., data=diamonds, facets = color ~ ., geom = "histogram", binwidth = 0.1, xlim = c(0, 3))
library(lda)
demo(lda)
library(lda)
demo(lda)
sample(1:dim(topic.proportions)[1], N)
demo(lda)
library(lda)
demo(lda)
tests_dir <- "/Users/jacobmenick/Desktop/Summer_2014_Research/tests/"
ggsave(file=tests_dir + "CRAN_cora_results.pdf")
ggsave(file= tests_dir + "CRAN_cora_results.pdf")
ggsave(file=paste(tests_dir,"CRAN_cora_results.pdf"))
This file runs the analysis on the 'cora' corpus from the CRAN lda package.  #
## We hope to achieve similar results as their demo so as test whether or not #
## this implementation of the Gibbs sampler is correct. #
###
## It assumes our current directory is the root of this project.  #
## We use the same parameters as are used in the demo(lda) script. #
#
# Load functions into workspace#
source("gibbs_prep.R")#
source("Gibbs.R")#
source("gibbs_output.R")#
#
# Load cora dataset into the workspace. #
library(lda)#
data(cora.documents)#
data(cora.vocab)#
#
# Get the dtm for cora. #
dtmCORA <- lda_corpus_to_dtm(cora.documents, cora.vocab)#
#
# Stemify the corpus. #
new_corpus_objects <- stemmify(dtmCORA, cora.vocab)#
dtmCORA <- new_corpus_objects[[1]]#
cora.vocab <- new_corpus_objects[[2]]#
#
# I realize the list operations are probably counterintuitive. #
# I couldn't think of a better way to return multiple objects.#
# The remove.stopwords function affects both the dtm and the vocab, though. #
#
# Remove some stop words. #
stop.words <- c("paper", "result", "model", "show", "method", "approach")#
#
new_corpus_objects <- remove.stopwords(dtmCORA, cora.vocab, stop.words)#
dtmCORA <- new_corpus_objects[[1]]#
cora.vocab <- new_corpus_objects[[2]]#
# Set Parameters for the Gibbs Sampler, #
n.sim <- 25#
K <- 10#
alpha <- 0.1#
beta <- 0.1#
#
# Run Gibbs Sampler and store results in the variable 'paramsCORA'#
paramsCORA <- gibbs.sampler.lda(dtmCORA, n.sim, K, alpha, beta)#
#
# Now let's visualize the results of the model fit with ggplot2. #
#
numDocs <- 10#
#
# Get a melted dataframe#
df <- get_plottable_df_lda(dtmCORA, cora.vocab, paramsCORA, numDocs)#
#
# Plot the results. #
plot <- get_primitive_qplot(df, numDocs)#
print(plot)
library(lda)
demo(lda)
library(lda)
demo(lda)
ggsave(file="/Users/jacobmenick/Desktop/Summer_2014_Research/r_scripts/LdaGibbs/figures/CRAN_cora_results.pdf")
demo(lda)
library(lda)
demo(lda)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar", stat="identity") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar", stat="bin") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(421)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(8675309)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(8675309)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(8675309)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
demo(lda)
topic.proportions.df
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      theme(axis.text.x = element_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=document, ylab="proportion",#
      data=topic.proportions.df, geom="bar") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
qplot(topic, value, fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
qplot(topic, value, fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
topic.proportions.df
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
qplot(topic, value/sum(value), fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
Runs the demo from the lda package.  I am putting this in its own dedicated script#
## so that I can mess with the seed for the random number generator and see how#
## the results vary. #
#
library(lda)#
require("ggplot2")#
require("reshape2")#
#
data(cora.documents)#
data(cora.vocab)#
#
theme_set(theme_bw())#
#
# Woo! #
set.seed(420)#
#
K <- 10 # Num clusters#
#
result <- lda.collapsed.gibbs.sampler(cora.documents,#
				      K,  ## Num clusters#
				      cora.vocab,#
				      25,#
				      0.1,#
				      0.1,#
				      compute.log.likelihood=TRUE)#
#
# Get the top words in the cluster#
top.words <- top.topic.words(result$topics, 5, by.score=TRUE)#
# Number of documents to display			  #
N <- 10    #
#
topic.proportions <- t(result$document_sums) / colSums(result$document_sums)#
#
topic.porportions <- #
  topic.proportions[sample(1:dim(topic.proportions)[1], N),]#
#
topic.proportions[is.na(topic.proportions)] <-  1 / K#
#
colnames(topic.proportions) <- apply(top.words, 2, paste, collapse=" ")#
#
topic.proportions.df <- melt(cbind(data.frame(topic.proportions),#
				   document=factor(1:N)),#
				   variable.name="topic",#
				    id.vars = "document")#
#
qplot(topic, value, fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
qplot(topic, value, fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="bin") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
qplot(topic, value/40, fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar",stat="identity") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
qplot(topic, value, fill=factor(document), ylab="proportion",#
      data=topic.proportions.df, geom="bar") +#
      opts(axis.text.x = theme_text(angle=90, hjust=1)) +#
      coord_flip() +#
      facet_wrap(~ document, ncol=5)
This file runs the analysis on the 'cora' corpus from the CRAN lda package.  #
## 1.  We hope to achieve similar results as #
##     their demo so as test whether or not his implementation of #
##     the Gibbs sampler is correct. #
###
## 2.  It assumes our current directory is the root of this project.  #
##     We use the same parameters as are used in the demo(lda) script. #
###
## 3.  You may want to try a few runs with different seeds.  #
##     Because the Gibbs sampler is non-deterministic, #
##     And we are doing a relatively samll number of iterations,#
##     The initial state of the Markov Chain can have big effects on #
##     the output.  #
#
# Load functions into workspace#
source("gibbs_prep.R")#
source("Gibbs.R")#
source("gibbs_output.R")#
#
# Load cora dataset into the workspace. #
library(lda)#
data(cora.documents)#
data(cora.vocab)#
#
# Get the dtm for cora. #
dtmCORA <- lda_corpus_to_dtm(cora.documents, cora.vocab)#
#
# Convert the dtm to a tm 'corpus' for pre-processing. #
corpusCORA <- dtm_to_corpus(dtmCORA)#
corpusCORA <- process_corpus(corpusCORA)#
corpusCORA <- stem_corpus(corpusCORA)#
#
# Convert back to a dtm.  #
dtmCORA <- get_dtm_matrix(corpusCORA)#
cora.vocab <- get_vocabObj(dtmCORA)#
# Remove some stop words. Blei mentioned in a video that they did this as well.  #
stop.words <- c("paper", "result", "model", "show", "method", "approach", "base", #
                "data", "general", "function", "perform", "comput", "present")#
#
new_corpus_objects <- remove.stopwords(dtmCORA, cora.vocab, stop.words)#
dtmCORA <- new_corpus_objects[[1]]#
cora.vocab <- new_corpus_objects[[2]]#
# Set Parameters for the Gibbs Sampler, #
n.sim <- 25#
K <- 10#
alpha <- 0.1#
beta <- 0.1#
#
# Run Gibbs Sampler and store results in the variable 'paramsCORA'#
paramsCORA <- gibbs.sampler.lda(dtmCORA, n.sim, K, alpha, beta)#
#
# Now let's visualize the results of the model fit with ggplot2. #
#
numDocs <- 10#
#
# Get a melted dataframe#
df <- get_plottable_df_lda(dtmCORA, cora.vocab, paramsCORA, numDocs)#
#
# Plot the results. #
plot <- get_primitive_qplot(df, numDocs)#
print(plot)
library('lda')
demo(lda)
top.words
?apply
top.topic.words
path_to_patents <- "/Users/jacobmenick/Desktop/datasets/patents_jan07"
path_to_scripts <- "/Users/jacobmenick/Desktop/Summer_2014_Research/r_scripts/LdaGibbs"
setwd(path_to_scripts)
source("gibbs_prep.R")
source("gibbs_output.R")
library('topicmodels')
corpusPatents <- get_corpus(path_to_patents)
dtmPatents <- get_dtm_matrix(corpusPatents)
vocabPatents <- colnames(dtmPatents)
stop.words <- c("title","abstract")
new_objects <- remove.stopwords(dtmPatents, vocabPatents, stop.words)
dtmPatents <- new_objects[[1]]
vocabPatents <- new_objects[[2]]
inspect.frequent.words(dtmPatents, vocabPatents, 20)
k <- 20
SEED <- 420
vem_model <- LDA(dtmPatents, k = k, control = list(seed = SEED))
vem_model.beta
beta(vem_model)
vem_model
vem_model@beta
terms(vem_model)
terms(vem_model, 5)
Phi <- vem_model@beta
Theta <- vem_model@gamma
theta[1,]
Theta[1,]
params <- list(Phi, Theta)
df <- get_plottable_df(corpusPatents, dtmPatents, vocabPatents, params, 10)
plot <- get_primitive_qplot(df, 10)
print(plot)
dim(dtmPatents)
